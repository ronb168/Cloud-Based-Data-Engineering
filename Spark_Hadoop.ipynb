{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_Hadoop.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QxkdsnQR_gSo",
        "-lpQq1QM6Aus"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Spark**"
      ],
      "metadata": {
        "id": "QxkdsnQR_gSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy\n",
        "\n",
        "!pip install pyspark\n",
        "os.environ[\"PYSPARK_PYTHON\"] = sys.executable"
      ],
      "metadata": {
        "id": "Vot9QdIpkWU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8274b84b-1d9e-473d-f675-856ec4ecdcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 52.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=61199f57c428f531f32085cfaf8d5307240e971610e7c2f287f9da18a479e143\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf, SQLContext"
      ],
      "metadata": {
        "id": "WoKikfxX13Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SparkConf - Configuration Before SQL & Content\n",
        "conf = SparkConf().setAppName(\"babies\").setMaster(\"local[*]\") \n",
        "sc = SparkContext(conf=conf)\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "id": "Pd-pbXzA16ID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d816c88d-115e-4b1e-b5d9-3ff9a14e44d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.textFile(\"baby_names.csv\")"
      ],
      "metadata": {
        "id": "vLZKh1TW1_83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "babies_header  = rdd.first() \n",
        "header = sc.parallelize([babies_header])\n",
        "rdd = rdd.subtract(header)"
      ],
      "metadata": {
        "id": "EHA1yCiTUqts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in rdd.take(5):\n",
        "  print(line)"
      ],
      "metadata": {
        "id": "SRUO5nYG2IaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b6e977-c529-4fb4-834b-c6df08d0edf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2013,GAVIN,ST LAWRENCE,M,9\n",
            "2013,LEVI,ST LAWRENCE,M,9\n",
            "2013,ELIZA,KINGS,F,16\n",
            "2013,ZARA,KINGS,F,16\n",
            "2013,JONATHAN,NEW YORK,M,51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple"
      ],
      "metadata": {
        "id": "5DlpBYVr2UTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Baby = namedtuple('Baby', ['year', \n",
        "                               'first_name', \n",
        "                               'country', \n",
        "                               'sex', \n",
        "                               'count'])"
      ],
      "metadata": {
        "id": "wg5oQ-Kl2WR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_to_baby(line):\n",
        "    cols = line.split(\",\")\n",
        "    return Baby(year = cols[0],\n",
        "                  first_name = cols[1].upper(),\n",
        "                  country = cols[2].upper(),\n",
        "                  sex = cols[3],\n",
        "                  count = int(cols[4])) "
      ],
      "metadata": {
        "id": "6FQfDAEg2o9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baby_rdd = rdd.map(map_to_baby)\n",
        "df = baby_rdd.toDF()"
      ],
      "metadata": {
        "id": "5dxHOZFZ3PQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KuUqrUVSmn5",
        "outputId": "3fb7c41b-cbe7-41ec-8389-c653418d6956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+-----------+---+-----+\n",
            "|year|first_name|    country|sex|count|\n",
            "+----+----------+-----------+---+-----+\n",
            "|2013|     GAVIN|ST LAWRENCE|  M|    9|\n",
            "|2013|      LEVI|ST LAWRENCE|  M|    9|\n",
            "|2013|     ELIZA|      KINGS|  F|   16|\n",
            "|2013|      ZARA|      KINGS|  F|   16|\n",
            "|2013|  JONATHAN|   NEW YORK|  M|   51|\n",
            "+----+----------+-----------+---+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-MKsa3ROG0F",
        "outputId": "bd5d7f3b-5876-4f2a-b5aa-554d2d93300f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- year: string (nullable = true)\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- sex: string (nullable = true)\n",
            " |-- count: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, avg, count\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import col, expr\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "QrtIQkcbiyvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. How many males has born in New York? "
      ],
      "metadata": {
        "id": "MjSVZsGXnfqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((df[\"sex\"] == \"M\") & (df[\"country\"] == \"NEW YORK\"))\\\n",
        "  .select(sum(\"count\").alias(\"MalesBabeisBornInNY\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXXSuB8ph4X9",
        "outputId": "45ab84c9-c0dd-45d9-c39d-aa26ceb2ed02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|MalesBabeisBornInNY|\n",
            "+-------------------+\n",
            "|              45884|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. What is the country with the most amount of female newborn?"
      ],
      "metadata": {
        "id": "at6D9DQ0oMui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"sex\"] == \"F\").groupBy(df[\"country\"])\\\n",
        "  .agg(sum(\"count\").alias(\"FemaleBabies\"))\\\n",
        "  .orderBy(\"FemaleBabies\", ascending=False)\\\n",
        "  .select(\"country\").show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooSP5y4KlMrj",
        "outputId": "7ae1123b-2782-4fc4-e280-70829d5890b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|country|\n",
            "+-------+\n",
            "|  KINGS|\n",
            "+-------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. What is the distribution of gender?"
      ],
      "metadata": {
        "id": "Eic-Qm2ioaCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_babies = df.select(sum(\"count\").alias(\"total_babies\")).take(1)[0]\\\n",
        "  .asDict()['total_babies']\n",
        "  \n",
        "total_babies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yoxao88wXyL",
        "outputId": "de6612cd-0f6f-4a89-c2f9-5aa59b2ca734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "943428"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rollup(\"sex\").agg(sum(\"count\").alias(\"total_babies_per_sex\"))\\\n",
        "  .withColumn('perc_total_babies_per_sex', F.round((F.col('total_babies_per_sex') / total_babies ) * 100, 2)) \\\n",
        "  .withColumn('perc_total_babies_per_sex',F.concat(F.col('perc_total_babies_per_sex').cast(StringType()),F.lit('%')))\\\n",
        "  .orderBy(\"total_babies_per_sex\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Pkx3dTMsvK",
        "outputId": "d18158e0-8d7d-48ba-98c5-39b420591b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+-------------------------+\n",
            "| sex|total_babies_per_sex|perc_total_babies_per_sex|\n",
            "+----+--------------------+-------------------------+\n",
            "|   F|              397693|                   42.15%|\n",
            "|   M|              545735|                   57.85%|\n",
            "|null|              943428|                   100.0%|\n",
            "+----+--------------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. What is the most popular name?\n"
      ],
      "metadata": {
        "id": "y1FZ81mlolzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(df[\"first_name\"]).agg(sum(\"count\").alias(\"babies_per_name\"))\\\n",
        "  .orderBy(\"babies_per_name\", ascending=False).select(\"first_name\").show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YywSLJXwrymu",
        "outputId": "805619c6-f3e3-48bd-df97-5e24054af377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|first_name|\n",
            "+----------+\n",
            "|   MICHAEL|\n",
            "+----------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. For each country, display the average amount of newborn per year."
      ],
      "metadata": {
        "id": "i3zu75UxooV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"country\").pivot(\"year\").agg(F.round(avg(\"count\"), 3)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP-GXyHUjBR0",
        "outputId": "df9520b3-af6f-4083-a568-031909e84b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+-----+-----+-----+-----+-----+-----+-----+\n",
            "|     country| 2007| 2008| 2009| 2010| 2011| 2012| 2013| 2014|\n",
            "+------------+-----+-----+-----+-----+-----+-----+-----+-----+\n",
            "|      FULTON|  6.5|5.875|6.364|5.667|  5.9|5.333|5.333|  5.5|\n",
            "|ST. LAWRENCE| null| null| null| null| null| null| null|  6.4|\n",
            "| CATTARAUGUS|  6.0|5.964|6.393|6.034|5.722|6.409|  6.5|6.684|\n",
            "|     STEUBEN|6.846|6.679|6.615|6.878|6.292|6.176|6.308|6.094|\n",
            "|       YATES| null| null|5.333| null| null| null| null| null|\n",
            "+------------+-----+-----+-----+-----+-----+-----+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. For each year, display the average of gender count. \n"
      ],
      "metadata": {
        "id": "Z33nPZuTosJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"year\").pivot(\"sex\").agg(sum(\"count\")).withColumn(\"TOTAL\", expr(\"F+M\"))\\\n",
        "  .withColumn('F', F.round((F.col('F') / col(\"TOTAL\")) * 100, 2)) \\\n",
        "  .withColumn('F',F.concat(F.col('F').cast(StringType()),F.lit('%')))\\\n",
        "  .withColumn('M', F.round((F.col('M') / col(\"TOTAL\")) * 100, 2)) \\\n",
        "  .withColumn('M',F.concat(F.col('M').cast(StringType()),F.lit('%')))\\\n",
        "  .orderBy(\"year\").select(\"year\", \"F\", \"M\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubEig9Jw_LK2",
        "outputId": "7a0c4e17-0a9f-4021-f117-0d7620ebe39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------+\n",
            "|year|     F|     M|\n",
            "+----+------+------+\n",
            "|2007|42.13%|57.87%|\n",
            "|2008| 41.5%| 58.5%|\n",
            "|2009|41.64%|58.36%|\n",
            "|2010|41.81%|58.19%|\n",
            "|2011|41.97%|58.03%|\n",
            "|2012|41.69%|58.31%|\n",
            "|2013|42.21%|57.79%|\n",
            "|2014|44.14%|55.86%|\n",
            "+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.pandas as ps"
      ],
      "metadata": {
        "id": "fqJ_zWawCcbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54119b63-5b8c-4d33-f2c8-3413f3b1fc3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = ps.read_csv(\"baby_names.csv\")"
      ],
      "metadata": {
        "id": "0nYr_Dl2DK7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6185cf-b29c-4b3b-fed1-e5028e1d24ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns = ['year', 'first_name', 'county', 'sex', 'count']"
      ],
      "metadata": {
        "id": "V03mQ57SPUAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OJiEDwMDDZ2H",
        "outputId": "55bc9724-deb5-4cba-abd3-4a77a47daf80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year first_name       county sex  count\n",
              "0  2013      GAVIN  ST LAWRENCE   M      9\n",
              "1  2013       LEVI  ST LAWRENCE   M      9\n",
              "2  2013      LOGAN     NEW YORK   M     44\n",
              "3  2013     HUDSON     NEW YORK   M     49\n",
              "4  2013    GABRIEL     NEW YORK   M     50\n",
              "5  2013   THEODORE     NEW YORK   M     51\n",
              "6  2013      ELIZA        KINGS   F     16\n",
              "7  2013  MADELEINE        KINGS   F     16\n",
              "8  2013       ZARA        KINGS   F     16\n",
              "9  2013      DAISY        KINGS   F     16"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>first_name</th>\n",
              "      <th>county</th>\n",
              "      <th>sex</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013</td>\n",
              "      <td>GAVIN</td>\n",
              "      <td>ST LAWRENCE</td>\n",
              "      <td>M</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013</td>\n",
              "      <td>LEVI</td>\n",
              "      <td>ST LAWRENCE</td>\n",
              "      <td>M</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>LOGAN</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>M</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013</td>\n",
              "      <td>HUDSON</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>M</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013</td>\n",
              "      <td>GABRIEL</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>M</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2013</td>\n",
              "      <td>THEODORE</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>M</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2013</td>\n",
              "      <td>ELIZA</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2013</td>\n",
              "      <td>MADELEINE</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2013</td>\n",
              "      <td>ZARA</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2013</td>\n",
              "      <td>DAISY</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create two new boolean columns “Sex_M” and “Sex_F”, represent the dummy version of “Sex” column. "
      ],
      "metadata": {
        "id": "gCnQfBxgo21h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = ps.get_dummies(data = df1,columns = ['sex'])"
      ],
      "metadata": {
        "id": "hfET8BpGDcRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Zvswq_UrVMSO",
        "outputId": "66eff638-f97c-4ec7-eacd-35468d955e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year first_name       county  count  sex_F  sex_M\n",
              "0  2013      GAVIN  ST LAWRENCE      9      0      1\n",
              "1  2013       LEVI  ST LAWRENCE      9      0      1\n",
              "2  2013      LOGAN     NEW YORK     44      0      1\n",
              "3  2013     HUDSON     NEW YORK     49      0      1\n",
              "4  2013    GABRIEL     NEW YORK     50      0      1\n",
              "5  2013   THEODORE     NEW YORK     51      0      1\n",
              "6  2013      ELIZA        KINGS     16      1      0\n",
              "7  2013  MADELEINE        KINGS     16      1      0\n",
              "8  2013       ZARA        KINGS     16      1      0\n",
              "9  2013      DAISY        KINGS     16      1      0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>first_name</th>\n",
              "      <th>county</th>\n",
              "      <th>count</th>\n",
              "      <th>sex_F</th>\n",
              "      <th>sex_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013</td>\n",
              "      <td>GAVIN</td>\n",
              "      <td>ST LAWRENCE</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013</td>\n",
              "      <td>LEVI</td>\n",
              "      <td>ST LAWRENCE</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>LOGAN</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013</td>\n",
              "      <td>HUDSON</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013</td>\n",
              "      <td>GABRIEL</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2013</td>\n",
              "      <td>THEODORE</td>\n",
              "      <td>NEW YORK</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2013</td>\n",
              "      <td>ELIZA</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2013</td>\n",
              "      <td>MADELEINE</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2013</td>\n",
              "      <td>ZARA</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2013</td>\n",
              "      <td>DAISY</td>\n",
              "      <td>KINGS</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sex column has already been removed when using the \"get_dummies\" function**"
      ],
      "metadata": {
        "id": "98SKoGgKGHoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = df1.to_spark()"
      ],
      "metadata": {
        "id": "T5LMw-ftO_WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec725750-db8e-48e9-8049-2428930b6f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhsXfC5xXSZK",
        "outputId": "3c1e50b1-e3e5-4be9-f929-a7449c9697b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- year: integer (nullable = true)\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- county: string (nullable = true)\n",
            " |-- count: integer (nullable = true)\n",
            " |-- sex_F: byte (nullable = true)\n",
            " |-- sex_M: byte (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in rdd1.take(3):\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZzgllXbIk_v",
        "outputId": "ef637f10-ce11-490a-e07a-5c4621af280c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(year=2013, first_name='GAVIN', county='ST LAWRENCE', count=9, sex_F=0, sex_M=1)\n",
            "Row(year=2013, first_name='LEVI', county='ST LAWRENCE', count=9, sex_F=0, sex_M=1)\n",
            "Row(year=2013, first_name='LOGAN', county='NEW YORK', count=44, sex_F=0, sex_M=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = rdd1.toDF(\"year\", \"first_name\", \"county\", \"count\", \"sex_F\", \"sex_M\")"
      ],
      "metadata": {
        "id": "B1LbgsRmZatB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nJ0zWFVZ4Nr",
        "outputId": "72cff9b4-7019-4a06-b725-400cdcf1e7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+-----------+-----+-----+-----+\n",
            "|year|first_name|     county|count|sex_F|sex_M|\n",
            "+----+----------+-----------+-----+-----+-----+\n",
            "|2013|     GAVIN|ST LAWRENCE|    9|    0|    1|\n",
            "|2013|      LEVI|ST LAWRENCE|    9|    0|    1|\n",
            "|2013|     LOGAN|   NEW YORK|   44|    0|    1|\n",
            "|2013|    HUDSON|   NEW YORK|   49|    0|    1|\n",
            "|2013|   GABRIEL|   NEW YORK|   50|    0|    1|\n",
            "|2013|  THEODORE|   NEW YORK|   51|    0|    1|\n",
            "|2013|     ELIZA|      KINGS|   16|    1|    0|\n",
            "|2013| MADELEINE|      KINGS|   16|    1|    0|\n",
            "|2013|      ZARA|      KINGS|   16|    1|    0|\n",
            "|2013|     DAISY|      KINGS|   16|    1|    0|\n",
            "+----+----------+-----------+-----+-----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAuFGqPqaGEH",
        "outputId": "4231fe0c-3dd9-4c98-b34d-7c45ea078a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- year: integer (nullable = true)\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- county: string (nullable = true)\n",
            " |-- count: integer (nullable = true)\n",
            " |-- sex_F: byte (nullable = true)\n",
            " |-- sex_M: byte (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.rollup(\"sex_F\").agg(sum(\"count\").alias(\"total_babies_per_sex\"))\\\n",
        "  .withColumn('perc_total_babies_per_sex', F.round((F.col('total_babies_per_sex') / total_babies ) * 100, 2)) \\\n",
        "  .withColumn('perc_total_babies_per_sex',F.concat(F.col('perc_total_babies_per_sex').cast(StringType()),F.lit('%')))\\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7n7VAOQzRmK",
        "outputId": "e42f86a4-d8ea-4e7b-abad-e304e837e525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+-------------------------+\n",
            "|sex_F|total_babies_per_sex|perc_total_babies_per_sex|\n",
            "+-----+--------------------+-------------------------+\n",
            "|    1|              397693|                   42.15%|\n",
            "|    0|              545735|                   57.85%|\n",
            "| null|              943428|                   100.0%|\n",
            "+-----+--------------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hadoop**"
      ],
      "metadata": {
        "id": "-lpQq1QM6Aus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qpEHyLKoqcXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a359db50-fd2e-42f2-f241-e367c733bb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
        "!tar -xzvf hadoop-3.3.2.tar.gz\n",
        "!cp -r hadoop-3.3.2/ /usr/local/\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
      ],
      "metadata": {
        "id": "3nC5zfPEP01y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To set java path, go to /usr/local/hadoop-3.3.2/etc/hadoop/hadoop-env.sh then\n",
        "\n",
        ". . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . ."
      ],
      "metadata": {
        "id": "dWAlPusnsQ9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file omg_mapper.py\n",
        "#!/usr/bin/env python\n",
        "import sys\n",
        "import re\n",
        "\n",
        "patterns = [\"omg\", \"oh-my-god\", \"oh my god\"]\n",
        "# We will convert each line to lower case\n",
        "\n",
        "for line in sys.stdin:\n",
        "  try:\n",
        "    # format of each line - Ross: Hey there!\n",
        "    line = line.strip().lower() # ross: hey there!\n",
        "    sentence = line.split(\":\")[1]\n",
        "    for pattern in patterns:\n",
        "      if re.search(pattern, sentence):\n",
        "        speaker = line.split(\":\")[0].title() # Ross\n",
        "        print('%s\\t%s' % (speaker, 1))\n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "Rvp2sBSanHIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdc9683-1ccf-4669-af1c-29f6b1559d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting omg_mapper.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file omg_reducer.py\n",
        "#!/usr/bin/env python\n",
        "import sys\n",
        "\n",
        "current_speaker = None\n",
        "current_count = 0\n",
        "speaker = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "    line = line.strip()\n",
        "    try:\n",
        "        speaker, count = line.split('\\t', 1)\n",
        "        count = int(count)\n",
        "    except ValueError:\n",
        "        continue\n",
        "        \n",
        "    if current_speaker == speaker:\n",
        "        current_count += count\n",
        "    else:\n",
        "        if current_speaker:\n",
        "            print('%s\\t%s' % (current_speaker, current_count))\n",
        "        current_count = count\n",
        "        current_speaker = speaker\n",
        "\n",
        "if current_speaker == speaker:\n",
        "    print('%s\\t%s' % (current_speaker, current_count))"
      ],
      "metadata": {
        "id": "Xv-ByNbonMcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210a7691-e718-4ce0-9a3e-9d2dc08caf80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting omg_reducer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x omg_reducer.py \n",
        "!chmod +x omg_mapper.py "
      ],
      "metadata": {
        "id": "7Rb6zJxAntMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file Makefile\n",
        "\n",
        "HADOOP_VERSION=3.3.2\n",
        "HADOOP_HOME=/export/hadoop-${HADOOP_VERSION}\n",
        "HADOOP_TOOLS=usr/local/hadoop-3.3.2/share/hadoop/tools/lib\n",
        "HADOOP_JAR = \"/content/hadoop-3.3.2/share/hadoop/tools/lib/hadoop-streaming-3.3.2.jar\"\n",
        "HDFS_DIR=/content/${USER}\n",
        " \n",
        "SAMPLES = ./drive/MyDrive/FriendsEpisodes/*.txt\n",
        "\n",
        "copy_to_hdfs: ${SAMPLES}\n",
        "\t/usr/local/hadoop-3.3.2/bin/hdfs dfs -mkdir -p ${HDFS_DIR}/friends\n",
        "\t/usr/local/hadoop-3.3.2/bin/hdfs dfs -put $^ ${HDFS_DIR}/friends\n",
        "\n",
        "run_with_hadoop: \n",
        "\t/usr/local/hadoop-3.3.2/bin/hadoop jar ${HADOOP_JAR} \\\n",
        "    -file  ${PWD}/omg_mapper.py  -mapper  ${PWD}/omg_mapper.py \\\n",
        "    -file  ${PWD}/omg_reducer.py -reducer ${PWD}/omg_reducer.py \\\n",
        "    -input ${HDFS_DIR}/friends/*.txt -output ${HDFS_DIR}/omg_distribution"
      ],
      "metadata": {
        "id": "MJwFZV2amlrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ad11ea-db8a-42e6-ae66-1791551530a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Makefile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "/usr/local/hadoop-3.3.2/bin/hdfs dfs -rm -r friends  # remove input directory"
      ],
      "metadata": {
        "id": "oXD2uL0t2Y6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "make copy_to_hdfs # copy sample files to hdfs"
      ],
      "metadata": {
        "id": "0TuqP0SGoMMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1450da-21c0-4565-a6bb-8917e3730ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.2/bin/hdfs dfs -mkdir -p /content//friends\n",
            "/usr/local/hadoop-3.3.2/bin/hdfs dfs -put drive/MyDrive/FriendsEpisodes/1008.txt drive/MyDrive/FriendsEpisodes/314.txt drive/MyDrive/FriendsEpisodes/607.txt drive/MyDrive/FriendsEpisodes/214.txt drive/MyDrive/FriendsEpisodes/605.txt drive/MyDrive/FriendsEpisodes/114.txt drive/MyDrive/FriendsEpisodes/407.txt drive/MyDrive/FriendsEpisodes/602.txt drive/MyDrive/FriendsEpisodes/307.txt drive/MyDrive/FriendsEpisodes/207.txt drive/MyDrive/FriendsEpisodes/619.txt drive/MyDrive/FriendsEpisodes/518.txt drive/MyDrive/FriendsEpisodes/1002.txt drive/MyDrive/FriendsEpisodes/418.txt drive/MyDrive/FriendsEpisodes/319.txt drive/MyDrive/FriendsEpisodes/219.txt drive/MyDrive/FriendsEpisodes/118.txt drive/MyDrive/FriendsEpisodes/1007.txt drive/MyDrive/FriendsEpisodes/423.txt drive/MyDrive/FriendsEpisodes/911.txt drive/MyDrive/FriendsEpisodes/918.txt drive/MyDrive/FriendsEpisodes/323.txt drive/MyDrive/FriendsEpisodes/1013.txt drive/MyDrive/FriendsEpisodes/909.txt drive/MyDrive/FriendsEpisodes/818.txt drive/MyDrive/FriendsEpisodes/223.txt drive/MyDrive/FriendsEpisodes/1003.txt drive/MyDrive/FriendsEpisodes/723.txt drive/MyDrive/FriendsEpisodes/609.txt drive/MyDrive/FriendsEpisodes/123.txt drive/MyDrive/FriendsEpisodes/509.txt drive/MyDrive/FriendsEpisodes/618.txt drive/MyDrive/FriendsEpisodes/1011.txt drive/MyDrive/FriendsEpisodes/210.txt drive/MyDrive/FriendsEpisodes/322.txt drive/MyDrive/FriendsEpisodes/209.txt drive/MyDrive/FriendsEpisodes/908.txt drive/MyDrive/FriendsEpisodes/109.txt drive/MyDrive/FriendsEpisodes/110.txt drive/MyDrive/FriendsEpisodes/921.txt drive/MyDrive/FriendsEpisodes/318.txt drive/MyDrive/FriendsEpisodes/708.txt drive/MyDrive/FriendsEpisodes/218.txt drive/MyDrive/FriendsEpisodes/721.txt drive/MyDrive/FriendsEpisodes/906.txt drive/MyDrive/FriendsEpisodes/811.txt drive/MyDrive/FriendsEpisodes/905.txt drive/MyDrive/FriendsEpisodes/621.txt drive/MyDrive/FriendsEpisodes/802.txt drive/MyDrive/FriendsEpisodes/804.txt drive/MyDrive/FriendsEpisodes/806.txt drive/MyDrive/FriendsEpisodes/521.txt drive/MyDrive/FriendsEpisodes/705.txt drive/MyDrive/FriendsEpisodes/604.txt drive/MyDrive/FriendsEpisodes/507.txt drive/MyDrive/FriendsEpisodes/409.txt drive/MyDrive/FriendsEpisodes/309.txt drive/MyDrive/FriendsEpisodes/204.txt drive/MyDrive/FriendsEpisodes/107.txt drive/MyDrive/FriendsEpisodes/321.txt drive/MyDrive/FriendsEpisodes/504.txt drive/MyDrive/FriendsEpisodes/512.txt drive/MyDrive/FriendsEpisodes/206.txt drive/MyDrive/FriendsEpisodes/221.txt drive/MyDrive/FriendsEpisodes/520.txt drive/MyDrive/FriendsEpisodes/1004.txt drive/MyDrive/FriendsEpisodes/901.txt drive/MyDrive/FriendsEpisodes/1016.txt drive/MyDrive/FriendsEpisodes/420.txt drive/MyDrive/FriendsEpisodes/907.txt drive/MyDrive/FriendsEpisodes/320.txt drive/MyDrive/FriendsEpisodes/913.txt drive/MyDrive/FriendsEpisodes/813.txt drive/MyDrive/FriendsEpisodes/822.txt drive/MyDrive/FriendsEpisodes/220.txt drive/MyDrive/FriendsEpisodes/805.txt drive/MyDrive/FriendsEpisodes/624.txt drive/MyDrive/FriendsEpisodes/702.txt drive/MyDrive/FriendsEpisodes/120.txt drive/MyDrive/FriendsEpisodes/502.txt drive/MyDrive/FriendsEpisodes/402.txt drive/MyDrive/FriendsEpisodes/302.txt drive/MyDrive/FriendsEpisodes/505.txt drive/MyDrive/FriendsEpisodes/405.txt drive/MyDrive/FriendsEpisodes/413.txt drive/MyDrive/FriendsEpisodes/713.txt drive/MyDrive/FriendsEpisodes/313.txt drive/MyDrive/FriendsEpisodes/205.txt drive/MyDrive/FriendsEpisodes/324.txt drive/MyDrive/FriendsEpisodes/613.txt drive/MyDrive/FriendsEpisodes/517.txt drive/MyDrive/FriendsEpisodes/823.txt drive/MyDrive/FriendsEpisodes/417.txt drive/MyDrive/FriendsEpisodes/317.txt drive/MyDrive/FriendsEpisodes/608.txt drive/MyDrive/FriendsEpisodes/217.txt drive/MyDrive/FriendsEpisodes/513.txt drive/MyDrive/FriendsEpisodes/117.txt drive/MyDrive/FriendsEpisodes/408.txt drive/MyDrive/FriendsEpisodes/821.txt drive/MyDrive/FriendsEpisodes/308.txt drive/MyDrive/FriendsEpisodes/208.txt drive/MyDrive/FriendsEpisodes/717.txt drive/MyDrive/FriendsEpisodes/711.txt drive/MyDrive/FriendsEpisodes/108.txt drive/MyDrive/FriendsEpisodes/623.txt drive/MyDrive/FriendsEpisodes/718.txt drive/MyDrive/FriendsEpisodes/617.txt drive/MyDrive/FriendsEpisodes/701.txt drive/MyDrive/FriendsEpisodes/817.txt drive/MyDrive/FriendsEpisodes/709.txt drive/MyDrive/FriendsEpisodes/523.txt drive/MyDrive/FriendsEpisodes/113.txt drive/MyDrive/FriendsEpisodes/919.txt drive/MyDrive/FriendsEpisodes/611.txt drive/MyDrive/FriendsEpisodes/1010.txt drive/MyDrive/FriendsEpisodes/511.txt drive/MyDrive/FriendsEpisodes/819.txt drive/MyDrive/FriendsEpisodes/411.txt drive/MyDrive/FriendsEpisodes/1012.txt drive/MyDrive/FriendsEpisodes/311.txt drive/MyDrive/FriendsEpisodes/719.txt drive/MyDrive/FriendsEpisodes/211.txt drive/MyDrive/FriendsEpisodes/722.txt drive/MyDrive/FriendsEpisodes/111.txt drive/MyDrive/FriendsEpisodes/815.txt drive/MyDrive/FriendsEpisodes/1001.txt drive/MyDrive/FriendsEpisodes/917.txt drive/MyDrive/FriendsEpisodes/519.txt drive/MyDrive/FriendsEpisodes/903.txt drive/MyDrive/FriendsEpisodes/809.txt drive/MyDrive/FriendsEpisodes/419.txt drive/MyDrive/FriendsEpisodes/904.txt drive/MyDrive/FriendsEpisodes/801.txt drive/MyDrive/FriendsEpisodes/803.txt drive/MyDrive/FriendsEpisodes/703.txt drive/MyDrive/FriendsEpisodes/603.txt drive/MyDrive/FriendsEpisodes/503.txt drive/MyDrive/FriendsEpisodes/403.txt drive/MyDrive/FriendsEpisodes/303.txt drive/MyDrive/FriendsEpisodes/203.txt drive/MyDrive/FriendsEpisodes/103.txt drive/MyDrive/FriendsEpisodes/704.txt drive/MyDrive/FriendsEpisodes/119.txt drive/MyDrive/FriendsEpisodes/421.txt drive/MyDrive/FriendsEpisodes/202.txt drive/MyDrive/FriendsEpisodes/922.txt drive/MyDrive/FriendsEpisodes/404.txt drive/MyDrive/FriendsEpisodes/102.txt drive/MyDrive/FriendsEpisodes/305.txt drive/MyDrive/FriendsEpisodes/416.txt drive/MyDrive/FriendsEpisodes/910.txt drive/MyDrive/FriendsEpisodes/316.txt drive/MyDrive/FriendsEpisodes/707.txt drive/MyDrive/FriendsEpisodes/216.txt drive/MyDrive/FriendsEpisodes/105.txt drive/MyDrive/FriendsEpisodes/116.txt drive/MyDrive/FriendsEpisodes/810.txt drive/MyDrive/FriendsEpisodes/622.txt drive/MyDrive/FriendsEpisodes/710.txt drive/MyDrive/FriendsEpisodes/916.txt drive/MyDrive/FriendsEpisodes/610.txt drive/MyDrive/FriendsEpisodes/522.txt drive/MyDrive/FriendsEpisodes/510.txt drive/MyDrive/FriendsEpisodes/808.txt drive/MyDrive/FriendsEpisodes/410.txt drive/MyDrive/FriendsEpisodes/422.txt drive/MyDrive/FriendsEpisodes/310.txt drive/MyDrive/FriendsEpisodes/601.txt drive/MyDrive/FriendsEpisodes/501.txt drive/MyDrive/FriendsEpisodes/401.txt drive/MyDrive/FriendsEpisodes/301.txt drive/MyDrive/FriendsEpisodes/201.txt drive/MyDrive/FriendsEpisodes/101.txt drive/MyDrive/FriendsEpisodes/222.txt drive/MyDrive/FriendsEpisodes/508.txt drive/MyDrive/FriendsEpisodes/715.txt drive/MyDrive/FriendsEpisodes/1014.txt drive/MyDrive/FriendsEpisodes/122.txt drive/MyDrive/FriendsEpisodes/515.txt drive/MyDrive/FriendsEpisodes/415.txt drive/MyDrive/FriendsEpisodes/315.txt drive/MyDrive/FriendsEpisodes/915.txt drive/MyDrive/FriendsEpisodes/215.txt drive/MyDrive/FriendsEpisodes/115.txt drive/MyDrive/FriendsEpisodes/814.txt drive/MyDrive/FriendsEpisodes/714.txt drive/MyDrive/FriendsEpisodes/614.txt drive/MyDrive/FriendsEpisodes/902.txt drive/MyDrive/FriendsEpisodes/514.txt drive/MyDrive/FriendsEpisodes/807.txt drive/MyDrive/FriendsEpisodes/414.txt drive/MyDrive/FriendsEpisodes/406.txt drive/MyDrive/FriendsEpisodes/106.txt drive/MyDrive/FriendsEpisodes/612.txt drive/MyDrive/FriendsEpisodes/121.txt drive/MyDrive/FriendsEpisodes/606.txt drive/MyDrive/FriendsEpisodes/506.txt drive/MyDrive/FriendsEpisodes/706.txt drive/MyDrive/FriendsEpisodes/306.txt drive/MyDrive/FriendsEpisodes/104.txt drive/MyDrive/FriendsEpisodes/812.txt drive/MyDrive/FriendsEpisodes/412.txt drive/MyDrive/FriendsEpisodes/912.txt drive/MyDrive/FriendsEpisodes/304.txt drive/MyDrive/FriendsEpisodes/712.txt drive/MyDrive/FriendsEpisodes/516.txt drive/MyDrive/FriendsEpisodes/1005.txt drive/MyDrive/FriendsEpisodes/816.txt drive/MyDrive/FriendsEpisodes/1006.txt drive/MyDrive/FriendsEpisodes/224.txt drive/MyDrive/FriendsEpisodes/914.txt drive/MyDrive/FriendsEpisodes/1009.txt drive/MyDrive/FriendsEpisodes/920.txt drive/MyDrive/FriendsEpisodes/112.txt drive/MyDrive/FriendsEpisodes/716.txt drive/MyDrive/FriendsEpisodes/820.txt drive/MyDrive/FriendsEpisodes/124.txt drive/MyDrive/FriendsEpisodes/312.txt drive/MyDrive/FriendsEpisodes/720.txt drive/MyDrive/FriendsEpisodes/325.txt drive/MyDrive/FriendsEpisodes/620.txt drive/MyDrive/FriendsEpisodes/1015.txt /content//friends\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "/usr/local/hadoop-3.3.2/bin/hdfs dfs -ls friends # list files on hdfs"
      ],
      "metadata": {
        "id": "Mj5a7WBVobFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "/usr/local/hadoop-3.3.2/bin/hdfs dfs -rm -r -f omg_distribution # Remove output directory on hdfs"
      ],
      "metadata": {
        "id": "IAROp2UF2Q-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45101881-855f-4872-efda-27cc88fcd315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted omg_distribution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-25 19:36:20,178 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "make run_with_hadoop  # Run the hadoop streaming"
      ],
      "metadata": {
        "id": "ey43gjyRojem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "dist = {}\n",
        "with open(\"omg_distribution/part-00000\", \"r\") as file:\n",
        "  for line in file:\n",
        "    speaker, count = line.split('\\t')\n",
        "    dist[speaker] = int(count)\n",
        "results = reversed(sorted(dist.items(), key=operator.itemgetter(1)))\n",
        "results = list(results)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "eQau-f2Iwowp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8cc61a2-b7b7-4bd1-d6b5-9f7d336eaef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Rachel', 203), ('Monica', 181), ('Phoebe', 152), ('Ross', 90), ('Chandler', 67), ('Joey', 52), ('Emily', 6), ('All', 5), ('Rach', 4), ('Mona', 4), ('Janice', 4), ('Mr. Geller', 3), ('Jill', 3), ('Mrs. Potter', 2), ('Mrs. Geller', 2), ('Kathy', 2), ('Julie', 2), ('Joshua', 2), ('Frank', 2), ('Dennis Phillips', 2), ('Charlie', 2), ('Carol', 2), ('Amy', 2), ('Woman No. 1', 1), ('Woman', 1), ('Tim', 1), ('The Cooking Teacher', 1), ('Tag', 1), ('Store Guy', 1), ('Sarah', 1), ('Phoebe And Joey', 1), ('Nina', 1), ('Mrs. Waltham', 1), ('Mrs Green', 1), ('Mrs Buffay', 1), ('Monica And Phoebe', 1), ('Mnca', 1), ('Mindy', 1), ('Mike (To The Charity Guy)', 1), ('Melissa', 1), ('Luisa', 1), ('Lowell', 1), ('Lizzie', 1), ('Lisa', 1), ('Laura', 1), ('Kim', 1), ('Jessica Ashley', 1), ('Guest #2', 1), ('Frank Sr.', 1), ('Everybody', 1), ('Eric', 1), ('Elizabeth', 1), ('Dina', 1), ('Cynthia', 1), ('Cliff', 1), ('Chan', 1), ('Casting Director #1', 1), ('Cassie', 1), ('Caitlin', 1), ('Aurora', 1), ('Alice', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('omg_distribution.txt', 'w') as file:\n",
        "  for result in results:\n",
        "    file.write(\"%s\\t%s\\n\" % (result[0], result[1]))"
      ],
      "metadata": {
        "id": "vAVBXZ1_xHON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VeOxUifU_95t"
      }
    }
  ]
}